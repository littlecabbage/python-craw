# Zread Trending 日报生成器 - 开发文档

## 用户需求

用户提问：帮我用python实现这个需求：使用mcp工具获取网页内容 https://zread.ai/trending 并生成日报

用户希望：
1. 使用 Python 实现
2. 获取 https://zread.ai/trending 网页内容
3. 生成日报

## 解决方案

### 技术选型

由于网页是动态加载的（使用 JavaScript 渲染），需要选择能够处理动态内容的工具：

1. **Playwright** - 现代化的浏览器自动化工具，支持异步操作，能够完整渲染 JavaScript 内容
2. **BeautifulSoup4** - 用于解析 HTML 内容
3. **uv** - Python 项目管理工具（根据项目规则要求）

### 实现方案

1. **网页获取**：使用 Playwright 的异步 API 访问目标网页，等待页面完全加载
2. **内容解析**：使用 BeautifulSoup 解析 HTML，提取项目信息（仓库名、描述、标签、Stars）
3. **日报生成**：将解析的数据格式化为 Markdown 格式的日报文件

## 实现过程

### 1. 项目初始化

使用 `uv` 初始化项目：
```bash
uv init --no-readme
```

### 2. 依赖安装

安装必要的依赖包：
```bash
uv add playwright beautifulsoup4 lxml
uv run playwright install chromium
```

依赖说明：
- `playwright`: 浏览器自动化工具
- `beautifulsoup4`: HTML 解析库
- `lxml`: BeautifulSoup 的解析器（性能更好）

### 3. 核心功能实现

#### 3.1 网页内容获取 (`fetch_trending_content`)

使用 Playwright 异步 API：
- 启动 Chromium 浏览器（无头模式）
- 访问目标 URL
- 等待网络空闲，确保页面完全加载
- 获取页面 HTML 内容

#### 3.2 内容解析 (`parse_trending_data`)

解析策略：
1. 查找所有 `<a>` 标签，过滤出项目链接（格式：`/owner/repo`）
2. 从链接文本中提取：
   - 仓库名称（从 href 或文本中提取）
   - 描述信息（仓库名后的文本）
   - 标签（短文本，不含特殊字符）
   - Stars 数量（包含 'k' 或大数字）
3. 去重处理，确保每个项目只出现一次

#### 3.3 日报生成 (`generate_daily_report`)

生成 Markdown 格式的日报：
- 包含标题和生成时间
- 列出所有热门项目
- 每个项目包含：仓库名、描述、标签、Stars、链接
- 保存为文件：`zread_trending_report_YYYYMMDD.md`

### 4. 错误处理

- 如果解析失败，保存原始 HTML 供后续分析
- 捕获并打印异常信息，便于调试

## 使用方法

### 运行脚本

```bash
uv run python zread_trending_daily.py
```

### 输出文件

- 日报文件：`zread_trending_report_YYYYMMDD.md`
- 如果解析失败，会保存原始 HTML：`zread_trending_raw.html`

## 项目结构

```
python_craw/
├── pyproject.toml          # 项目配置文件
├── zread_trending_daily.py # 主程序
├── docs/
│   └── 开发文档.md         # 本文档
└── .venv/                  # 虚拟环境（uv 自动创建）
```

## 技术细节

### 为什么选择 Playwright 而不是 requests？

- 目标网页使用 JavaScript 动态加载内容
- requests + BeautifulSoup 只能获取初始 HTML，无法获取动态渲染的内容
- Playwright 能够完整执行 JavaScript，获取最终渲染的页面

### 解析策略说明

由于网页结构可能变化，解析逻辑采用了多种策略：
1. 从 href 提取仓库名（最可靠）
2. 从链接文本中提取描述和标签
3. 使用启发式方法识别 Stars 数量

如果解析失败，会保存原始 HTML，方便后续调整解析逻辑。

## 功能更新

### 2025-12-09: 添加中文翻译功能

根据用户需求，新增了中文翻译功能：

1. **自动翻译**：使用 Google Translate API 将英文内容翻译成中文
2. **智能检测**：自动检测文本语言，如果已经是中文则跳过翻译
3. **翻译范围**：翻译项目简介和亮点为中文
4. **错误处理**：翻译失败时保留原文，确保日报正常生成

### 2025-12-09: 添加项目简介和亮点功能

根据用户需求，新增了以下功能：

1. **项目详情获取**：访问每个项目的详情页面，提取更详细的信息
2. **简介提取**：从项目详情页面提取项目简介（description）
3. **亮点提取**：从项目详情页面提取项目亮点（highlights），最多5个
4. **并发优化**：使用信号量限制并发数（最多3个），避免服务器过载
5. **日报格式更新**：日报中现在包含：
   - **简介**：项目的详细描述
   - **亮点**：项目的关键特性列表
   - **标签**：项目标签
   - **Stars**：GitHub Stars 数量
   - **链接**：项目链接

### 实现细节

- 使用 `fetch_project_details()` 函数异步获取每个项目的详情
- 通过多种 CSS 选择器尝试提取简介和亮点
- 限制获取前20个项目的详情，避免耗时过长
- 使用 `asyncio.Semaphore` 控制并发，提高效率
- 使用 `deep-translator` 库将英文内容自动翻译成中文
- 智能检测文本语言，如果已经是中文则跳过翻译
- 添加翻译延迟，避免触发API速率限制

## 后续优化建议

1. **更精确的解析**：可以分析实际页面结构，使用更精确的 CSS 选择器
2. **数据验证**：添加数据验证逻辑，确保提取的信息完整
3. **定时任务**：可以添加定时执行功能，自动生成日报
4. **数据存储**：可以添加数据库存储，便于历史数据对比
5. **邮件推送**：可以添加邮件发送功能，自动发送日报
6. **亮点智能提取**：可以进一步优化亮点提取算法，识别更准确的项目特性

## 注意事项

1. 首次运行需要安装 Chromium 浏览器（约 130MB）
2. 网络连接需要稳定，确保能够访问目标网站
3. 如果网站结构变化，可能需要调整解析逻辑

